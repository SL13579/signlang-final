# tools/collect_landmarks.py
import cv2
import mediapipe as mp
import numpy as np
import os

# MediaPipe Hands ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1)

# ë°ì´í„° ì €ì¥ ë¦¬ìŠ¤íŠ¸
X_data = []
y_data = []

# videos í´ë”ì˜ mp4 ê¸°ì¤€ í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì˜ì–´ í‘œê¸°)
VIDEO_DIR = 'videos'
class_list = sorted([
    os.path.splitext(f)[0].lower() for f in os.listdir(VIDEO_DIR) if f.endswith('.mp4')
])
class_to_index = {name: idx for idx, name in enumerate(class_list)}

print(f"ğŸ’¡ í´ë˜ìŠ¤ ë§¤í•‘ (videos ê¸°ì¤€): {class_to_index}")
print("ğŸ’¡ ìˆ˜ì–´ ìëª¨ ì¢Œí‘œ ìˆ˜ì§‘ ì‹œì‘ (q í‚¤ë¡œ ì¢…ë£Œ)")

cap = cv2.VideoCapture(0)

while True:
    ret, frame = cap.read()
    if not ret:
        print("âŒ ì¹´ë©”ë¼ ì˜¤ë¥˜")
        break

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = hands.process(frame_rgb)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            # 21ê°œì˜ (x, y, z) ì¢Œí‘œ ì¶”ì¶œ â†’ flatten (63)
            landmarks = np.array([[lm.x, lm.y, lm.z] for lm in hand_landmarks.landmark]).flatten()

            # í”„ë ˆì„ í‘œì‹œ
            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

            cv2.putText(frame, "Enter label (e.g., g, n, d...)", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)
            cv2.imshow("Hand Landmark Collection", frame)

            # ë¼ë²¨ ì…ë ¥ ëŒ€ê¸° (í•œ ë²ˆë§Œ)
            key = cv2.waitKey(0)
            if key == ord('q'):
                cap.release()
                cv2.destroyAllWindows()
                break

            # ë¼ë²¨ ì…ë ¥ ë°›ê¸°
            label_input = input(f"ë¼ë²¨ ì…ë ¥ (videos ê¸°ì¤€ ì˜ì–´ í‘œê¸°: {class_list}): ").strip().lower()
            if label_input not in class_to_index:
                print("â— ìœ íš¨í•˜ì§€ ì•Šì€ ë¼ë²¨, ë¬´ì‹œ")
                continue

            X_data.append(landmarks)
            y_data.append(class_to_index[label_input])
            print(f"âœ… ì €ì¥ ì™„ë£Œ: {label_input}")

    cv2.imshow("Hand Landmark Collection", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()

# ë°ì´í„° ì €ì¥
os.makedirs("data", exist_ok=True)
np.save("data/X_landmarks.npy", np.array(X_data))
np.save("data/y_labels.npy", np.array(y_data))

print("ğŸ‰ ì¢Œí‘œ ë°ì´í„° ì €ì¥ ì™„ë£Œ: data/X_landmarks.npy, data/y_labels.npy")
