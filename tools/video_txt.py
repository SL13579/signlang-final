# tools/generate_dataset_with_mediapipe.py

import cv2
import os
import random
import mediapipe as mp

# ğŸ“ ê²½ë¡œ ì„¤ì •
BASE_DIR = os.path.dirname(os.path.abspath(__file__))  # .../tools
ROOT_DIR = os.path.abspath(os.path.join(BASE_DIR, '..'))  # .../
VIDEO_DIR = os.path.join(ROOT_DIR, 'videos')

# ğŸ”§ ì €ì¥ ê²½ë¡œ ì„¤ì •
IMG_TRAIN_DIR = os.path.join(ROOT_DIR, 'datasets/images/train')
LBL_TRAIN_DIR = os.path.join(ROOT_DIR, 'datasets/labels/train')
IMG_VAL_DIR = os.path.join(ROOT_DIR, 'datasets/images/val')
LBL_VAL_DIR = os.path.join(ROOT_DIR, 'datasets/labels/val')

# ğŸ”§ í´ë” ìƒì„±
os.makedirs(IMG_TRAIN_DIR, exist_ok=True)
os.makedirs(LBL_TRAIN_DIR, exist_ok=True)
os.makedirs(IMG_VAL_DIR, exist_ok=True)
os.makedirs(LBL_VAL_DIR, exist_ok=True)

# âœ‹ Mediapipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.6)

print("ğŸ’¡ Mediapipe ê¸°ë°˜ YOLO ë°ì´í„°ì…‹ ìƒì„± ì‹œì‘")

# ğŸ¯ YOLO í¬ë§· ë³€í™˜ í•¨ìˆ˜
def get_yolo_bbox(img_width, img_height, x_min, y_min, x_max, y_max):
    x_center = (x_min + x_max) / 2 / img_width
    y_center = (y_min + y_max) / 2 / img_height
    width = (x_max - x_min) / img_width
    height = (y_max - y_min) / img_height
    return x_center, y_center, width, height

# ğŸ§  í´ë˜ìŠ¤ ì´ë¦„ì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ
def get_label_index(name):
    try:
        return int(name.split('_')[0])  # '0_G' â†’ 0
    except:
        raise ValueError(f"âŒ ë¼ë²¨ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {name}")

# ğŸ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬
for video_file in os.listdir(VIDEO_DIR):
    if not video_file.endswith('.mp4'):
        continue

    label_name = '_'.join(os.path.splitext(video_file)[0].split('_')[:2])
    label_index = get_label_index(label_name)

    video_path = os.path.join(VIDEO_DIR, video_file)
    cap = cv2.VideoCapture(video_path)

    frame_count = 0
    saved_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(frame_rgb)

        if not results.multi_hand_landmarks:
            frame_count += 1
            continue

        image_h, image_w, _ = frame.shape
        x_list, y_list = [], []
        for landmark in results.multi_hand_landmarks[0].landmark:
            x_list.append(landmark.x * image_w)
            y_list.append(landmark.y * image_h)

        x_min, x_max = min(x_list), max(x_list)
        y_min, y_max = min(y_list), max(y_list)
        x_center, y_center, w, h = get_yolo_bbox(image_w, image_h, x_min, y_min, x_max, y_max)

        img_filename = f"{label_name}_{frame_count}.jpg"
        lbl_filename = f"{label_name}_{frame_count}.txt"

        if random.random() < 0.8:
            # í•™ìŠµ ë°ì´í„°
            cv2.imwrite(os.path.join(IMG_TRAIN_DIR, img_filename), frame)
            with open(os.path.join(LBL_TRAIN_DIR, lbl_filename), 'w') as f:
                f.write(f"{label_index} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\n")
        else:
            # ê²€ì¦ ë°ì´í„°
            cv2.imwrite(os.path.join(IMG_VAL_DIR, img_filename), frame)
            with open(os.path.join(LBL_VAL_DIR, lbl_filename), 'w') as f:
                f.write(f"{label_index} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\n")

        saved_count += 1
        frame_count += 1

    cap.release()
    print(f"âœ… {video_file} ì²˜ë¦¬ ì™„ë£Œ - {saved_count}ê°œ í”„ë ˆì„ ì €ì¥ë¨")

hands.close()
print("ğŸ‰ Mediapipe ê¸°ë°˜ YOLOv5 ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
